Problem: We want to parallelize the sequential pi computation using the monte-carlo-algorithm. Little communication between diffrent processes is needed, which leads us to the conclusion that using more processing power will be faster.

Approach: Since the monte-carlo-algorithm uses the relative distribution of random points within 2 defined shapes (a square and it's inner circle), we do not need to communicate between the processes, except for averaging the result of each process at the very end of the computation. Meaning each process computes the distribution of the local_sample_size = sample_size / size , where size is the number of processes. For sharing the result we can use MPI_Reduce(), which is straight-forward and easily implemented using a single line of code. MPI_SUM is specified as the used reduction-function. The root process is responsible for diving the total sum by the amount of processes. This is how we could limit the communication between processes to a bare minimum.